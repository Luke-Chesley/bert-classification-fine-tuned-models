{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 08:19:58.644973: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 08:19:58.791143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 08:19:59.262907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%run local_functions.py\n",
    "from local_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2500)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/wiki_movie_plots_deduped.csv\")\n",
    "df = df[[\"Plot\", \"Genre\"]]\n",
    "df = df.loc[df.Genre != \"unknown\"].reset_index(drop=True)\n",
    "df[\"text\"] = df[\"Plot\"].apply(text_normalization_2)\n",
    "df.drop(\"Plot\", axis=1, inplace=True)\n",
    "df = df[[\"text\", \"Genre\"]]\n",
    "# retain rows with top 100 genres\n",
    "top_100_genres = df[\"Genre\"].value_counts().head(100).index.tolist()\n",
    "df = df.loc[df[\"Genre\"].isin(top_100_genres)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(\n",
    "    training_df[\"Genre\"], columns=[\"Genre\"], prefix=\"\", prefix_sep=\"\"\n",
    ")\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "encoded_df_con = pd.concat([training_df[\"text\"], encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(encoded_df_con, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the split DataFrames into Datasets\n",
    "train = Dataset.from_pandas(train_df, split=\"train\")\n",
    "valid = Dataset.from_pandas(valid_df, split=\"validation\")\n",
    "test = Dataset.from_pandas(test_df, split=\"test\")\n",
    "\n",
    "dataset = DatasetDict({\"train\": train, \"validation\": valid, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    label\n",
    "    for label in dataset[\"train\"].features.keys()\n",
    "    if label not in [\"text\", \"__index_level_0__\"]\n",
    "]\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbce3a5fffc470998afc92b0b309e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12770 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a2bce1b84c41688753961f0ba621cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2863bea90d554c00a008a0ae34a172a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2737 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    LM,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels, threshold=0.5): # threshold = confidence threshold, important. 0.5 doesnt always work\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average=\"micro\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {\"f1\": f1_micro_average, \"roc_auc\": roc_auc, \"accuracy\": accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec67f9e9530f4354989c0f5372aa08c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1391, 'learning_rate': 1.8747651847213527e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0421, 'learning_rate': 1.7495303694427053e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0406, 'learning_rate': 1.624295554164058e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc7860779274654a64cf5f3a241ca19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.037935301661491394, 'eval_f1': 0.05471764293230445, 'eval_roc_auc': 0.5141827481980934, 'eval_accuracy': 0.028498355864084765, 'eval_runtime': 8.3207, 'eval_samples_per_second': 328.94, 'eval_steps_per_second': 41.223, 'epoch': 1.0}\n",
      "{'loss': 0.0377, 'learning_rate': 1.4990607388854104e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0346, 'learning_rate': 1.3738259236067628e-05, 'epoch': 1.57}\n",
      "{'loss': 0.034, 'learning_rate': 1.2485911083281152e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d45514707c4f3891f64933f441f13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03226800262928009, 'eval_f1': 0.34466403162055337, 'eval_roc_auc': 0.6187283872705868, 'eval_accuracy': 0.23894775301424917, 'eval_runtime': 8.292, 'eval_samples_per_second': 330.079, 'eval_steps_per_second': 41.365, 'epoch': 2.0}\n",
      "{'loss': 0.0311, 'learning_rate': 1.123356293049468e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0296, 'learning_rate': 9.981214777708203e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0297, 'learning_rate': 8.728866624921729e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a528aeae4478897886dad8bc4ac8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.031020186841487885, 'eval_f1': 0.38178198108511696, 'eval_roc_auc': 0.6391684473525906, 'eval_accuracy': 0.28023383266350016, 'eval_runtime': 8.3187, 'eval_samples_per_second': 329.018, 'eval_steps_per_second': 41.232, 'epoch': 3.0}\n",
      "{'loss': 0.0277, 'learning_rate': 7.476518472135255e-06, 'epoch': 3.13}\n",
      "{'loss': 0.0261, 'learning_rate': 6.2241703193487794e-06, 'epoch': 3.44}\n",
      "{'loss': 0.0263, 'learning_rate': 4.971822166562304e-06, 'epoch': 3.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f886f407c140bbab8ebd7e2b8b6747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03089076280593872, 'eval_f1': 0.38749384539635645, 'eval_roc_auc': 0.6427777962304817, 'eval_accuracy': 0.2875411033978809, 'eval_runtime': 8.2996, 'eval_samples_per_second': 329.776, 'eval_steps_per_second': 41.327, 'epoch': 4.0}\n",
      "{'loss': 0.0254, 'learning_rate': 3.71947401377583e-06, 'epoch': 4.07}\n",
      "{'loss': 0.0242, 'learning_rate': 2.4671258609893555e-06, 'epoch': 4.38}\n",
      "{'loss': 0.024, 'learning_rate': 1.2147777082028805e-06, 'epoch': 4.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d3cf5205cb4c1fbf2a6ae885331075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.030957674607634544, 'eval_f1': 0.39805115712545674, 'eval_roc_auc': 0.6482342607662301, 'eval_accuracy': 0.29850200949945194, 'eval_runtime': 8.312, 'eval_samples_per_second': 329.282, 'eval_steps_per_second': 41.266, 'epoch': 5.0}\n",
      "{'train_runtime': 741.9964, 'train_samples_per_second': 86.052, 'train_steps_per_second': 10.762, 'train_loss': 0.0372709420000529, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7985, training_loss=0.0372709420000529, metrics={'train_runtime': 741.9964, 'train_samples_per_second': 86.052, 'train_steps_per_second': 10.762, 'train_loss': 0.0372709420000529, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1dc193dfb84ef28c3acaaa281495d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.030957674607634544,\n",
       " 'eval_f1': 0.39805115712545674,\n",
       " 'eval_roc_auc': 0.6482342607662301,\n",
       " 'eval_accuracy': 0.29850200949945194,\n",
       " 'eval_runtime': 8.2304,\n",
       " 'eval_samples_per_second': 332.547,\n",
       " 'eval_steps_per_second': 41.675,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"bert-finetuned-wiki-movie-plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval \n",
    "#### should make subgenre preds count as correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-finetuned-wiki-movie-plots\"\n",
    ")\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = testing_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.1\n",
    "\n",
    "\n",
    "def inference(text):\n",
    "    encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "    encoding = {k: v.to(trainer.model.device) for k, v in encoding.items()}\n",
    "\n",
    "    outputs = trainer.model(**encoding)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # apply sigmoid + threshold\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(logits.squeeze().cpu())\n",
    "    predictions = np.zeros(probs.shape)\n",
    "    predictions[np.where(probs >= CONFIDENCE_THRESHOLD)] = 1\n",
    "    # turn predicted id's into actual label names\n",
    "    predicted_labels = [\n",
    "        id2label[idx] for idx, label in enumerate(predictions) if label == 1.0\n",
    "    ]\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of predictions that include correct class: 26.49% \n",
      "Multi_guess discount score: 26.49%\n",
      "Multi_positive_outcome discount score: 83.2%\n",
      "Percent of non-preds: 56.7083196317001% \n"
     ]
    }
   ],
   "source": [
    "ROWS_TO_EVALUATE = len(df_test)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.55  # 0.1 works well for low number of non-responses\n",
    "\n",
    "TOP_N_PREDS = 5  # number of top predictions to return\n",
    "\n",
    "\n",
    "# make predictions\n",
    "df_test[\"predicted_class\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    predict_class, args=(tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD)\n",
    ")  # args: text, tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD=0.5\n",
    "\n",
    "# calculate if prediction is correct\n",
    "df_test[\"correct\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    lambda row: int(row[\"Genre\"] in row[\"predicted_class\"]), axis=1\n",
    ")\n",
    "# calculate score (including penalty for guessing multiple categories) used to help find optimal confidence threshold\n",
    "df_test[\"correct_w_discount\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    multi_cat_guess_penalty,\n",
    "    axis=1,\n",
    "    args=(0.9,),  # muli_cat_guess_penalty (somewhere around 0.85 works well)\n",
    ")\n",
    "\n",
    "df_test[\"correct_w_non_preds\"] = df_test.apply(multi_positive_outcome, axis=1)\n",
    "\n",
    "# get top n predictions\n",
    "df_test[\"top_n_preds\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    n_most_likely_classes, args=(tokenizer, trainer, id2label, TOP_N_PREDS)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of predictions that include correct class: {round((df_test.correct.sum() / ROWS_TO_EVALUATE)*100, 2)}% \\nMulti_guess discount score: {round((df_test.correct_w_discount.sum() / ROWS_TO_EVALUATE)*100, 2)}%\\nMulti_positive_outcome discount score: {round((df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Percent of non-preds: {((df_test.correct_w_non_preds.sum() - df_test.correct.sum()) / ROWS_TO_EVALUATE*100)}% \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'drama': 0.527, 'thriller': 0.052, 'documentary': 0.037, 'horror': 0.026, 'science fiction': 0.024}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.top_n_preds[3:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
