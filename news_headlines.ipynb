{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 11:09:11.960667: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-31 11:09:11.981243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-31 11:09:12.289455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%run local_functions.py\n",
    "from local_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2500)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
    "df[\"text\"] = df[\"headline\"] + \" \" + df[\"short_description\"]\n",
    "df = df[[\"text\", \"category\"]]\n",
    "df[\"text\"] = df[\"text\"].apply(text_normalization_3)\n",
    "\n",
    "SAMPLE_SIZE = 25000\n",
    "\n",
    "df = df.sample(SAMPLE_SIZE, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(\n",
    "    training_df[\"category\"], columns=[\"category\"], prefix=\"\", prefix_sep=\"\"\n",
    ")\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "encoded_df_con = pd.concat([training_df[\"text\"], encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(encoded_df_con, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the split DataFrames into Datasets\n",
    "train = Dataset.from_pandas(train_df, split=\"train\")\n",
    "valid = Dataset.from_pandas(valid_df, split=\"validation\")\n",
    "test = Dataset.from_pandas(test_df, split=\"test\")\n",
    "\n",
    "dataset = DatasetDict({\"train\": train, \"validation\": valid, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    label\n",
    "    for label in dataset[\"train\"].features.keys()\n",
    "    if label not in [\"text\", \"__index_level_0__\"]\n",
    "]\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d8318c2d1b4d4daa23cb9a51db85b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d2e10380bf42d3835b4737ea6347a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501778361ffd47b1b42753e1b4564c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2813 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    LM,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(\n",
    "    predictions, labels, threshold=0.5\n",
    "):  # threshold = confidence threshold, important. 0.5 doesnt always work\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"micro\")\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average=\"micro\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {\"f1\": f1_micro_average, \"roc_auc\": roc_auc, \"accuracy\": accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc0e8ad7ae74ee0810eb2d659772e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1717, 'learning_rate': 1.87812309567337e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0944, 'learning_rate': 1.7562461913467398e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0832, 'learning_rate': 1.6343692870201096e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488dac004aa042b6bb830542bb2674e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07569011300802231, 'eval_f1': 0.35810446957458264, 'eval_roc_auc': 0.6172154182423758, 'eval_accuracy': 0.23648648648648649, 'eval_runtime': 16.6632, 'eval_samples_per_second': 168.755, 'eval_steps_per_second': 21.124, 'epoch': 1.0}\n",
      "{'loss': 0.0714, 'learning_rate': 1.5124923826934796e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0649, 'learning_rate': 1.3906154783668494e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0619, 'learning_rate': 1.2687385740402194e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400be7ad23554961bd1a45d764d99858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.060076575726270676, 'eval_f1': 0.5273446590644636, 'eval_roc_auc': 0.6999314783332755, 'eval_accuracy': 0.40291607396870555, 'eval_runtime': 16.6423, 'eval_samples_per_second': 168.967, 'eval_steps_per_second': 21.151, 'epoch': 2.0}\n",
      "{'loss': 0.0559, 'learning_rate': 1.1468616697135894e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0501, 'learning_rate': 1.0249847653869594e-05, 'epoch': 2.44}\n",
      "{'loss': 0.048, 'learning_rate': 9.03107861060329e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68c5ad8d84742e5a224e751156f079e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.055335044860839844, 'eval_f1': 0.565286263860602, 'eval_roc_auc': 0.7205313464941193, 'eval_accuracy': 0.4441678520625889, 'eval_runtime': 15.7393, 'eval_samples_per_second': 178.661, 'eval_steps_per_second': 22.364, 'epoch': 3.0}\n",
      "{'loss': 0.0465, 'learning_rate': 7.81230956733699e-06, 'epoch': 3.05}\n",
      "{'loss': 0.04, 'learning_rate': 6.59354052407069e-06, 'epoch': 3.35}\n",
      "{'loss': 0.0403, 'learning_rate': 5.374771480804388e-06, 'epoch': 3.66}\n",
      "{'loss': 0.0393, 'learning_rate': 4.156002437538087e-06, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803863a9ff704cffbdcf4fec1a8aab3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05379441753029823, 'eval_f1': 0.5949913644214162, 'eval_roc_auc': 0.7431044651840545, 'eval_accuracy': 0.4900426742532006, 'eval_runtime': 15.7378, 'eval_samples_per_second': 178.678, 'eval_steps_per_second': 22.367, 'epoch': 4.0}\n",
      "{'loss': 0.0352, 'learning_rate': 2.9372333942717856e-06, 'epoch': 4.27}\n",
      "{'loss': 0.0339, 'learning_rate': 1.7184643510054846e-06, 'epoch': 4.57}\n",
      "{'loss': 0.0346, 'learning_rate': 4.996953077391835e-07, 'epoch': 4.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b6d8803f5144e29b6fe1056db9d3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05378809571266174, 'eval_f1': 0.5902134080620823, 'eval_roc_auc': 0.7414347916594386, 'eval_accuracy': 0.4868421052631579, 'eval_runtime': 15.7379, 'eval_samples_per_second': 178.677, 'eval_steps_per_second': 22.366, 'epoch': 5.0}\n",
      "{'train_runtime': 1420.1854, 'train_samples_per_second': 46.209, 'train_steps_per_second': 5.777, 'train_loss': 0.060044924011323456, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8205, training_loss=0.060044924011323456, metrics={'train_runtime': 1420.1854, 'train_samples_per_second': 46.209, 'train_steps_per_second': 5.777, 'train_loss': 0.060044924011323456, 'epoch': 5.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e89face9a34bf8a7a50df4409d6ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05379441753029823,\n",
       " 'eval_f1': 0.5949913644214162,\n",
       " 'eval_roc_auc': 0.7431044651840545,\n",
       " 'eval_accuracy': 0.4900426742532006,\n",
       " 'eval_runtime': 16.5024,\n",
       " 'eval_samples_per_second': 170.399,\n",
       " 'eval_steps_per_second': 21.33,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"bert-finetuned-news-headlines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval - Training 23 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-finetuned-news-headlines\"\n",
    ")\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = testing_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mistake that leads to better brownies most...</td>\n",
       "      <td>FOOD &amp; DRINK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after the shooting at spu desolation consolati...</td>\n",
       "      <td>RELIGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gordon ramsay sued over unpaid wages by employ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fire breaks out at mexico s top refinery 9 peo...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 ways to make your marriage stronger grooms ...</td>\n",
       "      <td>WEDDINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>scott weiland died from toxic mix of drugs acc...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>15 reasons why october is the best time to vis...</td>\n",
       "      <td>TRAVEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>teen allegedly held captive is feeling a lot b...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>take a look at the best animal photos of the week</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>dramatic photos show texas under water with fl...</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       category\n",
       "0     the mistake that leads to better brownies most...   FOOD & DRINK\n",
       "1     after the shooting at spu desolation consolati...       RELIGION\n",
       "2     gordon ramsay sued over unpaid wages by employ...       BUSINESS\n",
       "3     fire breaks out at mexico s top refinery 9 peo...     WORLD NEWS\n",
       "4     20 ways to make your marriage stronger grooms ...       WEDDINGS\n",
       "...                                                 ...            ...\n",
       "6245  scott weiland died from toxic mix of drugs acc...  ENTERTAINMENT\n",
       "6246  15 reasons why october is the best time to vis...         TRAVEL\n",
       "6247  teen allegedly held captive is feeling a lot b...          CRIME\n",
       "6248  take a look at the best animal photos of the week          GREEN\n",
       "6249  dramatic photos show texas under water with fl...          GREEN\n",
       "\n",
       "[6250 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of predictions that include correct class: 41.36%\n",
      "Multi_guess discount score: 41.36%\n",
      "Multi_positive_outcome discount score: 89.79%\n",
      "Percent of non-preds: 48.43% \n",
      "Percent of wrong preds: 10.21%\n"
     ]
    }
   ],
   "source": [
    "ROWS_TO_EVALUATE = len(df_test)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.65  # 0.1 works well for low number of non-responses\n",
    "\n",
    "TOP_N_PREDS = 5  # number of top predictions to return\n",
    "\n",
    "\n",
    "# make predictions\n",
    "df_test[\"predicted_class\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    predict_class, args=(tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD)\n",
    ")  # args: text, tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD=0.5\n",
    "\n",
    "# calculate if prediction is correct\n",
    "df_test[\"correct\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    lambda row: int(row[\"category\"] in row[\"predicted_class\"]), axis=1\n",
    ")\n",
    "# calculate score (including penalty for guessing multiple categories) used to help find optimal confidence threshold\n",
    "df_test[\"correct_w_discount\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    multi_cat_guess_penalty,\n",
    "    axis=1,\n",
    "    args=(0.9,),  # muli_cat_guess_penalty (somewhere around 0.85 works well)\n",
    ")\n",
    "\n",
    "df_test[\"correct_w_non_preds\"] = df_test.apply(multi_positive_outcome, axis=1)\n",
    "\n",
    "# get top n predictions\n",
    "df_test[\"top_n_preds\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    n_most_likely_classes, args=(tokenizer, trainer, id2label, TOP_N_PREDS)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of predictions that include correct class: {round((df_test.correct.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_guess discount score: {round((df_test.correct_w_discount.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_positive_outcome discount score: {round((df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of non-preds: {round((df_test.correct_w_non_preds.sum() - df_test.correct.sum()) / ROWS_TO_EVALUATE*100, 2)}% \"\n",
    ")\n",
    "print(\n",
    "    f\"Percent of wrong preds: {round((1-(df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE))*100,2)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct</th>\n",
       "      <th>correct_w_discount</th>\n",
       "      <th>correct_w_non_preds</th>\n",
       "      <th>top_n_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mistake that leads to better brownies most...</td>\n",
       "      <td>FOOD &amp; DRINK</td>\n",
       "      <td>[FOOD &amp; DRINK]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'FOOD &amp; DRINK': 0.73, 'TASTE': 0.185, 'HEALTH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after the shooting at spu desolation consolati...</td>\n",
       "      <td>RELIGION</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'HEALTHY LIVING': 0.124, 'IMPACT': 0.12, 'REL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gordon ramsay sued over unpaid wages by employ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BUSINESS': 0.386, 'ENTERTAINMENT': 0.039, 'M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fire breaks out at mexico s top refinery 9 peo...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WORLD NEWS': 0.202, 'THE WORLDPOST': 0.135, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 ways to make your marriage stronger grooms ...</td>\n",
       "      <td>WEDDINGS</td>\n",
       "      <td>[WEDDINGS]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WEDDINGS': 0.703, 'DIVORCE': 0.121, 'STYLE &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>scott weiland died from toxic mix of drugs acc...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'HEALTHY LIVING': 0.225, 'CRIME': 0.049, 'WEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>15 reasons why october is the best time to vis...</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>[TRAVEL]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'TRAVEL': 0.891, 'HOME &amp; LIVING': 0.016, 'WEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>teen allegedly held captive is feeling a lot b...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CRIME': 0.548, 'BLACK VOICES': 0.054, 'WEIRD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>take a look at the best animal photos of the week</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GREEN': 0.197, 'WEIRD NEWS': 0.134, 'ENVIRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>dramatic photos show texas under water with fl...</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GREEN': 0.265, 'POLITICS': 0.216, 'ENVIRONME...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       category  \\\n",
       "0     the mistake that leads to better brownies most...   FOOD & DRINK   \n",
       "1     after the shooting at spu desolation consolati...       RELIGION   \n",
       "2     gordon ramsay sued over unpaid wages by employ...       BUSINESS   \n",
       "3     fire breaks out at mexico s top refinery 9 peo...     WORLD NEWS   \n",
       "4     20 ways to make your marriage stronger grooms ...       WEDDINGS   \n",
       "...                                                 ...            ...   \n",
       "6245  scott weiland died from toxic mix of drugs acc...  ENTERTAINMENT   \n",
       "6246  15 reasons why october is the best time to vis...         TRAVEL   \n",
       "6247  teen allegedly held captive is feeling a lot b...          CRIME   \n",
       "6248  take a look at the best animal photos of the week          GREEN   \n",
       "6249  dramatic photos show texas under water with fl...          GREEN   \n",
       "\n",
       "     predicted_class  correct  correct_w_discount  correct_w_non_preds  \\\n",
       "0     [FOOD & DRINK]        1                   1                    1   \n",
       "1                 []        0                   0                    1   \n",
       "2                 []        0                   0                    1   \n",
       "3                 []        0                   0                    1   \n",
       "4         [WEDDINGS]        1                   1                    1   \n",
       "...              ...      ...                 ...                  ...   \n",
       "6245              []        0                   0                    1   \n",
       "6246        [TRAVEL]        1                   1                    1   \n",
       "6247              []        0                   0                    1   \n",
       "6248              []        0                   0                    1   \n",
       "6249              []        0                   0                    1   \n",
       "\n",
       "                                            top_n_preds  \n",
       "0     {'FOOD & DRINK': 0.73, 'TASTE': 0.185, 'HEALTH...  \n",
       "1     {'HEALTHY LIVING': 0.124, 'IMPACT': 0.12, 'REL...  \n",
       "2     {'BUSINESS': 0.386, 'ENTERTAINMENT': 0.039, 'M...  \n",
       "3     {'WORLD NEWS': 0.202, 'THE WORLDPOST': 0.135, ...  \n",
       "4     {'WEDDINGS': 0.703, 'DIVORCE': 0.121, 'STYLE &...  \n",
       "...                                                 ...  \n",
       "6245  {'HEALTHY LIVING': 0.225, 'CRIME': 0.049, 'WEL...  \n",
       "6246  {'TRAVEL': 0.891, 'HOME & LIVING': 0.016, 'WEL...  \n",
       "6247  {'CRIME': 0.548, 'BLACK VOICES': 0.054, 'WEIRD...  \n",
       "6248  {'GREEN': 0.197, 'WEIRD NEWS': 0.134, 'ENVIRON...  \n",
       "6249  {'GREEN': 0.265, 'POLITICS': 0.216, 'ENVIRONME...  \n",
       "\n",
       "[6250 rows x 7 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
