{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 11:30:36.849094: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-18 11:30:36.869707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 11:30:37.241845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%run local_functions.py\n",
    "from local_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2500)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"datasets/drug-reviews.parquet\")[[\"condition\", \"review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"review\"].apply(text_normalization_3)\n",
    "df = df[[\"condition\", \"text\"]]\n",
    "\n",
    "N_CONDITIONS = 100\n",
    "top_n_conditions = df.condition.value_counts().head(N_CONDITIONS).index.to_list()\n",
    "\n",
    "df = df[df.condition.isin(top_n_conditions)]\n",
    "\n",
    "SAMPLE_SIZE = 25000\n",
    "\n",
    "df = df.sample(SAMPLE_SIZE, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Birth Control             5048\n",
       "Depression                1612\n",
       "Pain                      1107\n",
       "Anxiety                   1055\n",
       "Acne                       995\n",
       "                          ... \n",
       "Hot Flashes                 36\n",
       "Alcohol Withdrawal          34\n",
       "Pneumonia                   33\n",
       "Neuropathic Pain            33\n",
       "Ankylosing Spondylitis      33\n",
       "Name: condition, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(\n",
    "    training_df[\"condition\"], columns=[\"condition\"], prefix=\"\", prefix_sep=\"\"\n",
    ")\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "encoded_df_con = pd.concat([training_df[\"text\"], encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(encoded_df_con, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the split DataFrames into Datasets\n",
    "train = Dataset.from_pandas(train_df, split=\"train\")\n",
    "valid = Dataset.from_pandas(valid_df, split=\"validation\")\n",
    "test = Dataset.from_pandas(test_df, split=\"test\")\n",
    "\n",
    "dataset = DatasetDict({\"train\": train, \"validation\": valid, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    label\n",
    "    for label in dataset[\"train\"].features.keys()\n",
    "    if label not in [\"text\", \"__index_level_0__\"]\n",
    "]\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5570866c8f8a46e7bc649d883d76cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aa62d3c79940a78cbfe9647830dd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5b2dbcb49e4dc4a6d9828539088886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2813 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    LM,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 8\n",
    "metric_name = \"f1\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-drugs-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1bed6196eb4b9d8009190fb3955680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1641 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1537, 'learning_rate': 1.3906154783668494e-05, 'epoch': 0.3}\n",
      "{'loss': 0.053, 'learning_rate': 7.81230956733699e-06, 'epoch': 0.61}\n",
      "{'loss': 0.0495, 'learning_rate': 1.7184643510054846e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22479960f9a84073815bf3f145b96e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0484723336994648, 'eval_f1': 0.0, 'eval_roc_auc': 0.5, 'eval_accuracy': 0.0, 'eval_runtime': 16.6741, 'eval_samples_per_second': 168.645, 'eval_steps_per_second': 21.111, 'epoch': 1.0}\n",
      "{'train_runtime': 289.7486, 'train_samples_per_second': 45.298, 'train_steps_per_second': 5.664, 'train_loss': 0.08226439315033424, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1641, training_loss=0.08226439315033424, metrics={'train_runtime': 289.7486, 'train_samples_per_second': 45.298, 'train_steps_per_second': 5.664, 'train_loss': 0.08226439315033424, 'epoch': 1.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dcadfb406f410c8f1ba1f5e879cdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0484723336994648,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_roc_auc': 0.5,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_runtime': 16.6375,\n",
       " 'eval_samples_per_second': 169.016,\n",
       " 'eval_steps_per_second': 21.157,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-drugs-finetuned-sem_eval-english/checkpoint-1641\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
    "\n",
    "df_test = testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of predictions that include correct class: 20.69%\n",
      "Multi_guess discount score: 20.69%\n",
      "Multi_positive_outcome discount score: 20.69%\n",
      "Percent of non-preds: 0.0% \n",
      "Percent of wrong preds: 79.31%\n"
     ]
    }
   ],
   "source": [
    "ROWS_TO_EVALUATE = len(df_test)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.15  # 0.1 works well for low number of non-responses\n",
    "\n",
    "TOP_N_PREDS = 5  # number of top predictions to return\n",
    "\n",
    "\n",
    "# make predictions\n",
    "df_test[\"predicted_class\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    predict_class, args=(tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD)\n",
    ")  # args: text, tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD=0.5\n",
    "\n",
    "# calculate if prediction is correct\n",
    "df_test[\"correct\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    lambda row: int(row[\"condition\"] in row[\"predicted_class\"]), axis=1\n",
    ")\n",
    "# calculate score (including penalty for guessing multiple categories) used to help find optimal confidence threshold\n",
    "df_test[\"correct_w_discount\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    multi_cat_guess_penalty,\n",
    "    axis=1,\n",
    "    args=(0.9,),  # muli_cat_guess_penalty (somewhere around 0.85 works well)\n",
    ")\n",
    "\n",
    "df_test[\"correct_w_non_preds\"] = df_test.apply(multi_positive_outcome, axis=1)\n",
    "\n",
    "# get top n predictions\n",
    "df_test[\"top_n_preds\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    n_most_likely_classes, args=(tokenizer, trainer, id2label, TOP_N_PREDS)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of predictions that include correct class: {round((df_test.correct.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_guess discount score: {round((df_test.correct_w_discount.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_positive_outcome discount score: {round((df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of non-preds: {round((df_test.correct_w_non_preds.sum() - df_test.correct.sum()) / ROWS_TO_EVALUATE*100, 2)}% \"\n",
    ")\n",
    "print(\n",
    "    f\"Percent of wrong preds: {round((1-(df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE))*100,2)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct</th>\n",
       "      <th>correct_w_discount</th>\n",
       "      <th>correct_w_non_preds</th>\n",
       "      <th>top_n_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>High Blood Pressure</td>\n",
       "      <td>male 56 i started taking cozaar just 4 days ago to add to my current regiment of diuretic and be...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.187, 'Depression': 0.059, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24016</th>\n",
       "      <td>Acne</td>\n",
       "      <td>i have been using tri nessa for three months and it has been pretty good my doctor put it on me ...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.215, 'Depression': 0.059, 'Acne': 0.042, 'Anxiety': 0.041, 'Pain': 0.041}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9668</th>\n",
       "      <td>Birth Control</td>\n",
       "      <td>so i 039 ve had the nexplanon since december of 2013 prior to the nexplanon i was on the deep sh...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Birth Control': 0.215, 'Depression': 0.06, 'Acne': 0.042, 'Anxiety': 0.041, 'Pain': 0.041}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>Depression</td>\n",
       "      <td>i have tried lexapro zoloft calexa and brintellix my body does not tolerate meds well lexapro wa...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.194, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.039}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>Depression</td>\n",
       "      <td>this little pill caused me to have worsening suicidal thoughts i was on edge and crying daily th...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.189, 'Depression': 0.058, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24717</th>\n",
       "      <td>Birth Control</td>\n",
       "      <td>i am happy overall with the paragard copper iud i like that it 039 s hormone free birth control ...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Birth Control': 0.231, 'Depression': 0.062, 'Acne': 0.044, 'Anxiety': 0.042, 'Pain': 0.041}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Asthma</td>\n",
       "      <td>omg i 039 ve been taking singulair for one week i haven 039 t received my advair from the mail o...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.198, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.04}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>Urinary Tract Infection</td>\n",
       "      <td>when the doctor gave me this medicine i felt a lot better in my opinion it is effective</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.18, 'Depression': 0.059, 'Pain': 0.045, 'Anxiety': 0.042, 'Acne': 0.038}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21601</th>\n",
       "      <td>Constipation</td>\n",
       "      <td>so i 039 m 5 039 3 and 135 lbs i have tried dulcolax in the past for constipation but decided th...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.195, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.04}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>golf for me is not possible when the grass in the roughs is in bloom without allergy help i need...</td>\n",
       "      <td>[Birth Control]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Birth Control': 0.187, 'Depression': 0.059, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     condition  \\\n",
       "6868       High Blood Pressure   \n",
       "24016                     Acne   \n",
       "9668             Birth Control   \n",
       "13640               Depression   \n",
       "14018               Depression   \n",
       "...                        ...   \n",
       "24717            Birth Control   \n",
       "2578                    Asthma   \n",
       "10121  Urinary Tract Infection   \n",
       "21601             Constipation   \n",
       "3474         Allergic Rhinitis   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "6868   male 56 i started taking cozaar just 4 days ago to add to my current regiment of diuretic and be...   \n",
       "24016  i have been using tri nessa for three months and it has been pretty good my doctor put it on me ...   \n",
       "9668   so i 039 ve had the nexplanon since december of 2013 prior to the nexplanon i was on the deep sh...   \n",
       "13640  i have tried lexapro zoloft calexa and brintellix my body does not tolerate meds well lexapro wa...   \n",
       "14018  this little pill caused me to have worsening suicidal thoughts i was on edge and crying daily th...   \n",
       "...                                                                                                    ...   \n",
       "24717  i am happy overall with the paragard copper iud i like that it 039 s hormone free birth control ...   \n",
       "2578   omg i 039 ve been taking singulair for one week i haven 039 t received my advair from the mail o...   \n",
       "10121              when the doctor gave me this medicine i felt a lot better in my opinion it is effective   \n",
       "21601  so i 039 m 5 039 3 and 135 lbs i have tried dulcolax in the past for constipation but decided th...   \n",
       "3474   golf for me is not possible when the grass in the roughs is in bloom without allergy help i need...   \n",
       "\n",
       "       predicted_class  correct  correct_w_discount  correct_w_non_preds  \\\n",
       "6868   [Birth Control]        0                   0                    0   \n",
       "24016  [Birth Control]        0                   0                    0   \n",
       "9668   [Birth Control]        1                   1                    1   \n",
       "13640  [Birth Control]        0                   0                    0   \n",
       "14018  [Birth Control]        0                   0                    0   \n",
       "...                ...      ...                 ...                  ...   \n",
       "24717  [Birth Control]        1                   1                    1   \n",
       "2578   [Birth Control]        0                   0                    0   \n",
       "10121  [Birth Control]        0                   0                    0   \n",
       "21601  [Birth Control]        0                   0                    0   \n",
       "3474   [Birth Control]        0                   0                    0   \n",
       "\n",
       "                                                                                         top_n_preds  \n",
       "6868   {'Birth Control': 0.187, 'Depression': 0.059, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}  \n",
       "24016  {'Birth Control': 0.215, 'Depression': 0.059, 'Acne': 0.042, 'Anxiety': 0.041, 'Pain': 0.041}  \n",
       "9668    {'Birth Control': 0.215, 'Depression': 0.06, 'Acne': 0.042, 'Anxiety': 0.041, 'Pain': 0.041}  \n",
       "13640  {'Birth Control': 0.194, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.039}  \n",
       "14018  {'Birth Control': 0.189, 'Depression': 0.058, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}  \n",
       "...                                                                                              ...  \n",
       "24717  {'Birth Control': 0.231, 'Depression': 0.062, 'Acne': 0.044, 'Anxiety': 0.042, 'Pain': 0.041}  \n",
       "2578    {'Birth Control': 0.198, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.04}  \n",
       "10121   {'Birth Control': 0.18, 'Depression': 0.059, 'Pain': 0.045, 'Anxiety': 0.042, 'Acne': 0.038}  \n",
       "21601   {'Birth Control': 0.195, 'Depression': 0.059, 'Pain': 0.042, 'Anxiety': 0.041, 'Acne': 0.04}  \n",
       "3474   {'Birth Control': 0.187, 'Depression': 0.059, 'Pain': 0.043, 'Anxiety': 0.041, 'Acne': 0.039}  \n",
       "\n",
       "[6250 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
