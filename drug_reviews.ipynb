{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 19:29:33.094825: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-19 19:29:33.115315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 19:29:33.499068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%run local_functions.py\n",
    "from local_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2500)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"datasets/drug-reviews.parquet\")[[\"condition\", \"review\"]]\n",
    "\n",
    "df[\"text\"] = df[\"review\"].apply(text_normalization_3)\n",
    "df = df[[\"condition\", \"text\"]]\n",
    "\n",
    "N_CONDITIONS = 50\n",
    "top_n_conditions = df.condition.value_counts().head(N_CONDITIONS).index.to_list()\n",
    "\n",
    "df = df[df.condition.isin(top_n_conditions)]\n",
    "\n",
    "SAMPLE_SIZE = 25000\n",
    "\n",
    "df = df.sample(SAMPLE_SIZE, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes n samples from each condition to balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=[\"condition\", \"text\"])\n",
    "for condition in df.condition.unique():\n",
    "    c = df[df.condition == condition].sample(100, random_state=42)\n",
    "    new_df = pd.concat([new_df, c])\n",
    "\n",
    "df = new_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chronic Pain</td>\n",
       "      <td>i am taking this for my chronic pain along with hydrocodone 15mg x 4 daily for breakthrough pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chronic Pain</td>\n",
       "      <td>i find it nearly impossible to see how ms contin 30 is equivalent to 20mg of oxycodone in compar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chronic Pain</td>\n",
       "      <td>prescribed 30mg 3x daily used to be on opana 40mg opana was definitely a better solution because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chronic Pain</td>\n",
       "      <td>not great at all for relieving pain in my opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chronic Pain</td>\n",
       "      <td>i have been on this for almost a full month and can 039 t wait to get off of it the nausea has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Overactive Bladde</td>\n",
       "      <td>i was worried the patch would be intrusive but once i put it on the only thing i noticed was my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Overactive Bladde</td>\n",
       "      <td>worth every penny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Overactive Bladde</td>\n",
       "      <td>works very well for urgency etc an obscure side effect is diminished ability to achieve an erect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Overactive Bladde</td>\n",
       "      <td>after 4 years of taking trospium doctor tried me on flomax not only did it not work i expereince...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Overactive Bladde</td>\n",
       "      <td>for spinal cord injury 039 s this is a life saver i have a permanent catheter so paralyzing the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              condition  \\\n",
       "0          Chronic Pain   \n",
       "1          Chronic Pain   \n",
       "2          Chronic Pain   \n",
       "3          Chronic Pain   \n",
       "4          Chronic Pain   \n",
       "...                 ...   \n",
       "4995  Overactive Bladde   \n",
       "4996  Overactive Bladde   \n",
       "4997  Overactive Bladde   \n",
       "4998  Overactive Bladde   \n",
       "4999  Overactive Bladde   \n",
       "\n",
       "                                                                                                     text  \n",
       "0     i am taking this for my chronic pain along with hydrocodone 15mg x 4 daily for breakthrough pain...  \n",
       "1     i find it nearly impossible to see how ms contin 30 is equivalent to 20mg of oxycodone in compar...  \n",
       "2     prescribed 30mg 3x daily used to be on opana 40mg opana was definitely a better solution because...  \n",
       "3                                                       not great at all for relieving pain in my opinion  \n",
       "4     i have been on this for almost a full month and can 039 t wait to get off of it the nausea has b...  \n",
       "...                                                                                                   ...  \n",
       "4995  i was worried the patch would be intrusive but once i put it on the only thing i noticed was my ...  \n",
       "4996                                                                                    worth every penny  \n",
       "4997  works very well for urgency etc an obscure side effect is diminished ability to achieve an erect...  \n",
       "4998  after 4 years of taking trospium doctor tried me on flomax not only did it not work i expereince...  \n",
       "4999  for spinal cord injury 039 s this is a life saver i have a permanent catheter so paralyzing the ...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, testing_df = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.get_dummies(\n",
    "    training_df[\"condition\"], columns=[\"condition\"], prefix=\"\", prefix_sep=\"\"\n",
    ")\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "encoded_df_con = pd.concat([training_df[\"text\"], encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(encoded_df_con, test_size=0.3, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the split DataFrames into Datasets\n",
    "train = Dataset.from_pandas(train_df, split=\"train\")\n",
    "valid = Dataset.from_pandas(valid_df, split=\"validation\")\n",
    "test = Dataset.from_pandas(test_df, split=\"test\")\n",
    "\n",
    "dataset = DatasetDict({\"train\": train, \"validation\": valid, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    label\n",
    "    for label in dataset[\"train\"].features.keys()\n",
    "    if label not in [\"text\", \"__index_level_0__\"]\n",
    "]\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d37639f38fe4d43b5977674933ceb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cefa33551014290be1e3c9cde83a2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/562 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c927f6096c45778ad9a0fb8eded6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    # take a batch of texts\n",
    "    text = examples[\"text\"]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256)\n",
    "    # add labels\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    LM,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 8\n",
    "metric_name = \"f1\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-drugs-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b95d8d0cfad4374b869eae03aaa33bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f189882c0a841098a944c5bd1ebdfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12772415578365326, 'eval_f1': 0.0, 'eval_roc_auc': 0.5, 'eval_accuracy': 0.0, 'eval_runtime': 3.3256, 'eval_samples_per_second': 168.991, 'eval_steps_per_second': 21.349, 'epoch': 1.0}\n",
      "{'train_runtime': 58.8991, 'train_samples_per_second': 44.568, 'train_steps_per_second': 5.586, 'train_loss': 0.22950851301291794, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=329, training_loss=0.22950851301291794, metrics={'train_runtime': 58.8991, 'train_samples_per_second': 44.568, 'train_steps_per_second': 5.586, 'train_loss': 0.22950851301291794, 'epoch': 1.0})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ff2e310d484bdcb64be01ced8a9a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12772415578365326,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_roc_auc': 0.5,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_runtime': 3.3227,\n",
       " 'eval_samples_per_second': 169.142,\n",
       " 'eval_steps_per_second': 21.368,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-drugs-finetuned-sem_eval-english/checkpoint-329\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
    "\n",
    "df_test = testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of predictions that include correct class: 0.0%\n",
      "Multi_guess discount score: 0.0%\n",
      "Multi_positive_outcome discount score: 100.0%\n",
      "Percent of non-preds: 100.0% \n",
      "Percent of wrong preds: 0.0%\n"
     ]
    }
   ],
   "source": [
    "ROWS_TO_EVALUATE = len(df_test)\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.15  # 0.1 works well for low number of non-responses\n",
    "\n",
    "TOP_N_PREDS = 5  # number of top predictions to return\n",
    "\n",
    "\n",
    "# make predictions\n",
    "df_test[\"predicted_class\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    predict_class, args=(tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD)\n",
    ")  # args: text, tokenizer, trainer, id2label, CONFIDENCE_THRESHOLD=0.5\n",
    "\n",
    "# calculate if prediction is correct\n",
    "df_test[\"correct\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    lambda row: int(row[\"condition\"] in row[\"predicted_class\"]), axis=1\n",
    ")\n",
    "# calculate score (including penalty for guessing multiple categories) used to help find optimal confidence threshold\n",
    "df_test[\"correct_w_discount\"] = df_test[0:ROWS_TO_EVALUATE].apply(\n",
    "    multi_cat_guess_penalty,\n",
    "    axis=1,\n",
    "    args=(0.9,),  # muli_cat_guess_penalty (somewhere around 0.85 works well)\n",
    ")\n",
    "\n",
    "df_test[\"correct_w_non_preds\"] = df_test.apply(multi_positive_outcome, axis=1)\n",
    "\n",
    "# get top n predictions\n",
    "df_test[\"top_n_preds\"] = df_test[\"text\"][0:ROWS_TO_EVALUATE].apply(\n",
    "    n_most_likely_classes, args=(tokenizer, trainer, id2label, TOP_N_PREDS)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of predictions that include correct class: {round((df_test.correct.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_guess discount score: {round((df_test.correct_w_discount.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Multi_positive_outcome discount score: {round((df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE)*100, 2)}%\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Percent of non-preds: {round((df_test.correct_w_non_preds.sum() - df_test.correct.sum()) / ROWS_TO_EVALUATE*100, 2)}% \"\n",
    ")\n",
    "print(\n",
    "    f\"Percent of wrong preds: {round((1-(df_test.correct_w_non_preds.sum() / ROWS_TO_EVALUATE))*100,2)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct</th>\n",
       "      <th>correct_w_discount</th>\n",
       "      <th>correct_w_non_preds</th>\n",
       "      <th>top_n_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>i was addicted to opiates for 4years before this shot i finally feel like i 039 m not living a d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.092, 'Sinusitis': 0.092, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Psoriasis</td>\n",
       "      <td>been on enbrel for 4 years was totally clear for 2 years when i got a kidney infection went off ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.099, 'Insomnia': 0.096, 'Bacterial Infection': 0.093, 'Sinusitis': 0.092, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>Migraine</td>\n",
       "      <td>i have had migraines for approximately 20 yrs at 40 went into early menopause i had been migrain...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.092, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>only been on 15 mg for a week now and just upped to 30mg warning do not mix this with alcohol wh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.091, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Panic Disorde</td>\n",
       "      <td>klonopin helps my anxiety panic disorder and insomnia i take it on an as needed basis and it 039...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.093, 'H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>Abnormal Uterine Bleeding</td>\n",
       "      <td>i was 17 when i started on this pill because i had cysts on my ovaries this pill is a good pill ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.098, 'Insomnia': 0.096, 'Bacterial Infection': 0.093, 'Sinusitis': 0.091, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>Diabetes, Type 2</td>\n",
       "      <td>i have no appetite and i do have nausea i have lost 11 pounds this month i did miss 1 week of wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.098, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.093, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Migraine Prevention</td>\n",
       "      <td>i was given this medication to replace toprimate i took a pill friday night and saturday night 1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.094, 'Sinusitis': 0.091, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>Irritable Bowel Syndrome</td>\n",
       "      <td>i was skeptical and did not want to take this my doctor prescribed amitriptyline and citalopram ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.096, 'Bacterial Infection': 0.094, 'Sinusitis': 0.091, 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>Abnormal Uterine Bleeding</td>\n",
       "      <td>i began using this medicine after having very heavy bleeding for 2 month straight my periods wer...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.094, 'Psoriasis': 0.091, 'S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      condition  \\\n",
       "1501          Opiate Dependence   \n",
       "2586                  Psoriasis   \n",
       "2653                   Migraine   \n",
       "1055                    Anxiety   \n",
       "705               Panic Disorde   \n",
       "...                         ...   \n",
       "4141  Abnormal Uterine Bleeding   \n",
       "3168           Diabetes, Type 2   \n",
       "2478        Migraine Prevention   \n",
       "4214   Irritable Bowel Syndrome   \n",
       "4180  Abnormal Uterine Bleeding   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "1501  i was addicted to opiates for 4years before this shot i finally feel like i 039 m not living a d...   \n",
       "2586  been on enbrel for 4 years was totally clear for 2 years when i got a kidney infection went off ...   \n",
       "2653  i have had migraines for approximately 20 yrs at 40 went into early menopause i had been migrain...   \n",
       "1055  only been on 15 mg for a week now and just upped to 30mg warning do not mix this with alcohol wh...   \n",
       "705   klonopin helps my anxiety panic disorder and insomnia i take it on an as needed basis and it 039...   \n",
       "...                                                                                                   ...   \n",
       "4141  i was 17 when i started on this pill because i had cysts on my ovaries this pill is a good pill ...   \n",
       "3168  i have no appetite and i do have nausea i have lost 11 pounds this month i did miss 1 week of wo...   \n",
       "2478  i was given this medication to replace toprimate i took a pill friday night and saturday night 1...   \n",
       "4214  i was skeptical and did not want to take this my doctor prescribed amitriptyline and citalopram ...   \n",
       "4180  i began using this medicine after having very heavy bleeding for 2 month straight my periods wer...   \n",
       "\n",
       "     predicted_class  correct  correct_w_discount  correct_w_non_preds  \\\n",
       "1501              []        0                   0                    1   \n",
       "2586              []        0                   0                    1   \n",
       "2653              []        0                   0                    1   \n",
       "1055              []        0                   0                    1   \n",
       "705               []        0                   0                    1   \n",
       "...              ...      ...                 ...                  ...   \n",
       "4141              []        0                   0                    1   \n",
       "3168              []        0                   0                    1   \n",
       "2478              []        0                   0                    1   \n",
       "4214              []        0                   0                    1   \n",
       "4180              []        0                   0                    1   \n",
       "\n",
       "                                                                                              top_n_preds  \n",
       "1501  {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.092, 'Sinusitis': 0.092, 'P...  \n",
       "2586  {'Schizophrenia': 0.099, 'Insomnia': 0.096, 'Bacterial Infection': 0.093, 'Sinusitis': 0.092, 'P...  \n",
       "2653  {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.092, 'P...  \n",
       "1055  {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.091, 'P...  \n",
       "705   {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.093, 'H...  \n",
       "...                                                                                                   ...  \n",
       "4141  {'Schizophrenia': 0.098, 'Insomnia': 0.096, 'Bacterial Infection': 0.093, 'Sinusitis': 0.091, 'P...  \n",
       "3168  {'Schizophrenia': 0.098, 'Insomnia': 0.095, 'Bacterial Infection': 0.093, 'Sinusitis': 0.093, 'P...  \n",
       "2478  {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.094, 'Sinusitis': 0.091, 'P...  \n",
       "4214  {'Schizophrenia': 0.097, 'Insomnia': 0.096, 'Bacterial Infection': 0.094, 'Sinusitis': 0.091, 'P...  \n",
       "4180  {'Schizophrenia': 0.097, 'Insomnia': 0.095, 'Bacterial Infection': 0.094, 'Psoriasis': 0.091, 'S...  \n",
       "\n",
       "[1250 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
